---
output: pdf_document
---




```{r include=FALSE}
knitr::opts_chunk$set(fig.path = 'figurasR/',
                      echo = FALSE, warning = FALSE, message = FALSE,
                      fig.pos="H",out.extra = '',fig.align="center",out.width="95%",
                      cache=FALSE)

```




<!-- \setcounter{chapter}{2} -->
<!-- \setcounter{chapter}{2} escribir 2 para capítulo 3  -->
<!-- \pagenumbering{arabic} -->

\ifdefined\ifprincipal
\else
\setlength{\parindent}{1em}
\pagestyle{fancy}
\setcounter{tocdepth}{4}
\tableofcontents
<!-- \nocite{*} -->
\fi

\ifdefined\ifdoblecara
\fancyhead{}{}
\fancyhead[LE,RO]{\scriptsize\rightmark}
\fancyfoot[LO,RE]{\scriptsize\slshape \leftmark}
\fancyfoot[C]{}
\fancyfoot[LE,RO]{\footnotesize\thepage}
\else
\fancyhead{}{}
\fancyhead[RO]{\scriptsize\rightmark}
\fancyfoot[LO]{\scriptsize\slshape \leftmark}
\fancyfoot[C]{}
\fancyfoot[RO]{\footnotesize\thepage}
\fi
\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0.4pt}


```{r , message=FALSE , echo= FALSE}
library(tidyverse)
library(dplyr)
library(kableExtra)

library(plyr) # Transformación de los datos
library(dplyr)


library(lubridate)
library(ggplot2) # Visualización
library(hrbrthemes) # Temas 

library(TSA) # Series Temporales (B-C) (Not working)
library(tseries) # Test de raíz unitaria
library(forecast) # Diagnosis del modelo
library(MASS) # BN
library(AER)
library(Metrics)

```




```{r }
load("Datos/Dataset_Final.RData")
load("Datos/VENTAS_Dia_CALCIO.RData")
load("Datos/VENTAS_Dia_SCALCIO.RData")
load("Datos/VENTAS_Dia_TOTAL.RData")



load( "Datos/VENTAS_Dia_CALCIO_poiss.RData")
load("Datos/VENTAS_Dia_SCALCIO_poiss.RData")
load(  "Datos/VENTAS_Dia_TOTAL_poiss.RData")
```



```{r }
n=nrow(VolVentas_FECHA_poiss)
indin= 1:n
nent=ceiling(0.8*n) # número de registros de entrenamiento
ntest= n-nent # número de registros de testeo
set.seed(100822)
indient= sort(sample(indin,nent)) # índices de entrenamiento
inditest= setdiff(indin,indient) # índices de testeo

Ventas_TOTAL_ENT_poiss = VolVentas_FECHA_poiss[indient,-c(3,6)]
Ventas_TOTAL_TEST_poiss=VolVentas_FECHA_poiss[inditest,-c(3,6)]

Ventas_TOTAL_ENT= VolVentas_FECHA[indient,-c(3,6)]
Ventas_TOTAL_TEST=VolVentas_FECHA[inditest,-c(3,6)]


Ventas_CALCIO_ENT_poiss= VolVentas_CALCIO_FECHA_poiss[indient,-c(3,6)]
Ventas_CALCIO_TEST_poiss=VolVentas_CALCIO_FECHA_poiss[inditest,-c(3,6)]

Ventas_CALCIO_ENT= VolVentas_CALCIO_FECHA[indient,-c(3,6)]
Ventas_CALCIO_TEST=VolVentas_CALCIO_FECHA[inditest,-c(3,6)]



Ventas_SIN_CALCIO_ENT_poiss= VolVentas_SIN_CALCIO_FECHA_poiss[indient,-c(3,6)]
Ventas_SIN_CALCIO_TEST_poiss=VolVentas_SIN_CALCIO_FECHA_poiss[inditest,-c(3,6)]


Ventas_SIN_CALCIO_ENT= VolVentas_SIN_CALCIO_FECHA[indient,-c(3,6)]
Ventas_SIN_CALCIO_TEST=VolVentas_SIN_CALCIO_FECHA[inditest,-c(3,6)]
```




##### Modelo de Regresión de Poisson


Dado que la variable respuesta es discreta y de tipo conteo, se ha elegido este modelo en el que se asume que el volumen de ventas diario sigue una distribución de Poisson.

\[Y \sim Po(\mu), \quad \mu=\text{Número medio de ventas diario}\]





###### Modelado

En primer lugar, estimaremos los parámetros del modelo de regresión de Poisson, utilizando un conjunto de datos con variables dummy para el día de la semana y el mes del año, con la intención de representar la pertenencia de cada instancia a los distintos grupos.

También entrenaremos un modelo haciendo uso del conjunto de datos con las variables día de la semana y mes en forma de factor, para comprobar que modelo nos da unas mejores métricas.

Las variables explicativas son las siguientes:

- Variables dummy/factorizadas del día de la semana y el mes del año
- Precio medio con impuestos y descuento
- Día de la semana
- Mes del año

**Ventas totales**


```{r , echo=TRUE   ,  out.width = '70%'}
ModeloP_TOT_dummy = 
  glm(VENTAS~PRECIO_MEDIO_IMPUESTOS*DESCUENTO_MEDIO+
              (LUNES+MARTES+MIERCOLES+JUEVES+VIERNES+SABADO+DOMINGO)+
              (AGOSTO+SEPTIEMBRE+OCTUBRE+NOVIEMBRE+DICIEMBRE+ENERO),
      family = poisson(link = "log"),
      data=Ventas_TOTAL_ENT_poiss)
summary(ModeloP_TOT_dummy)
```




En la salida, podemos ver en la columna *estimate* la estimación de los coeficientes de regresión para las distintas variables, indicando, para las variables numérias, el cambio medio en el número de ventas que se produciría si aumentáramos en una unidad esa variable, y para las variables discretas, el cambio medio que provocaría en el número de ventas el que la variable tomara o no ese valor. También encontramos una columna para el error estándar, el valor del estadístico Z y el p-valor. Un p-valor menor que $\alpha = 0.05$ indicará que podemos considerar significativa esa variable de cara a predecir el volumen de ventas. Si por el contrario el p-valor es mayor que $\alpha$, concluiremos que dicha variable no influye en el volumen de ventasa.



Todas las variables que se refieren a meses o días de la semana influyen en el volumen de ventas:

- Con respecto al día de la semana, sabemos que el día de la semana que más ventas hay es el Sábado, por lo que estudiamos como afectan las ventas si es o no este día del fin de semana. $\hat\beta_{\text{Sábado} }  =2.500752 > 0$, es decir, el volumen de ventas aumentará, en media   $e^{2.500752}=$ `r round(exp(2.500752))` unidades si la compra se realiza un Sábado
- El mes donde hubo más ventas fué durante el mes de Octubre, y según este modelo el volumen de ventas aumentará, en media, manteniendo el resto de variables constante en $e^{0.108339}=$ `r round(exp(0.108339))` unidades si la compra se hace durante este mes.

Además, la interacción entre las variables descuento y precio medio también es significativa, es decir, la asociación que existe entre ambas varía en función de los diferentes valores que tomen.


Vamos ahora a entrenar el modelo para las variables factorizadas:

```{r , echo=TRUE}
ModeloP_TOT_factor= glm(VENTAS~PRECIO_MEDIO_IMPUESTOS+
                          DIA_SEMANA*MES+DESCUENTO_MEDIO,
                       family = poisson(link = "log"),
                       data=Ventas_TOTAL_ENT)
#summary(ModeloP_TOT_factor)
```



- La variable *descuento* puede considerarse significativa debido al p-valor $=1.9 * 10^{-14} < 0.05 = \alpha$
y según la estimación del coeficiente $\hat\beta_{\text{descuento}}=0.030274>0$ podemos afirmar que un aumento de la variable descuento en una unidad,
manteniendo el resto de variables constantes, hará que el volumen de ventas aumente en: $e^{0.030274}=$ `r round(exp(0.030274))` unidad.

- Si la venta se produce un Sábado, manteniendo constantes el resto de variables, el volumen de ventas disminuirá en  $e^{-0.296949}=$ `r round(exp(-0.296949))` unidad respecto a si se produjera otro día de la semana.

- Para el mes de Octubre el volumen de ventas disminuirá, en media en $e^{-0.264921}=$ `r round(exp(-0.264921))` unidad.

- Además, la interacción entre las variables día de la semana y mes del año es significativa, indicando que la asociación que existe entre ambas varía en función de los distintos valores que toman.



Para seleccionar un modelo adecuado, se ha hecho uso del criterio de información de Akaike, eligiendo aquel que nos de el menor AIC. A continuación se exponen los correspondientes valores del AIC para ambos modelos:

- Modelo con variables dummy: AIC= `r ModeloP_TOT_dummy$aic`
- Modelo con variables factorizadas: AIC= `r ModeloP_TOT_factor$aic`


El modelo seleccionado es el modelo para variables factorizadas, que nos da el menor valor del AIC, indicación de una mayor calidad del modelo estadístico.



A continuación, se procede a entrenar el modelo seleccionado para los datos de testeo haciendo uso de la función *predict*, mostrando las métricas que nos dan el rendimiento del modelo en forma de tabla.

```{r ,fig.pos = 'h'}
PRED_VOL_VENTAS_TOTAL=round(predict(ModeloP_TOT_factor, newdata = Ventas_TOTAL_TEST, type = "response"))
RSQUARE = function(valorReal,Prediccion){cor(valorReal,Prediccion)^2}


RMSE_Ent=rmse(Ventas_TOTAL_ENT$VENTAS,
              round(predict(ModeloP_TOT_factor, newdata = Ventas_TOTAL_ENT, type = "response")) ) 
R2_Ent=RSQUARE(Ventas_TOTAL_ENT$VENTAS,
            round(predict(ModeloP_TOT_factor, newdata = Ventas_TOTAL_ENT, type = "response")))

RMSE_Test = rmse(Ventas_TOTAL_TEST$VENTAS,PRED_VOL_VENTAS_TOTAL)
R2_Test =RSQUARE(Ventas_TOTAL_TEST$VENTAS,PRED_VOL_VENTAS_TOTAL)

DATOS = c("Datos entrenamiento","Datos Test")
R2=c(R2_Ent,R2_Test)
RMSE=c(RMSE_Ent,RMSE_Test)
```






```{r}
library(tidyverse)
library(kableExtra)
cbind.data.frame(DATOS,R2,RMSE) %>% 
  kable(booktabs=TRUE) %>% 
  kableExtra::kable_styling(latex_options = c("striped","HOLD_position") )
```

El modelo obtenido explica el `r round(100*R2_Ent,2)`% de la variabilidad total de los datos en el conjunto de entrenamiento y el `r round(100*R2_Test,2)`% para los datos de testeo, no pudiendo considerar este como un buen modelo para explicar el volumen de ventas total.  El valor del error cuadrático medio indica que el modelo se va a equivocar de media, en `r round(RMSE[2])` ventas, que es un valor alto para el volumen de ventas que se está considerando, ya que hay días que se venden menos de 700 items. El modelo no consigue generalizar correctamente.


**Contraste de bondad de ajuste**

Para comprobar si se trata o no de un buen modelo, realizamos el contraste de bondad de ajuste, donde se contrastan las siguientes hipótesis:

\[
\left\{
\begin{array}{ll}
H_{0}: &  \text{El ajuste lineal es bueno}\\
H_{1}: & \text{El ajuste no es bueno}
\end{array}
\right.
\]

El p-valor del contraste: `r pchisq(ModeloP_TOT_factor$deviance, df=ModeloP_TOT_factor$df.residual, lower.tail=FALSE)` $< 0.05 = \alpha$ y por tanto, no existen evidencias significativas para afirmar que el modelo es adecuadao



**Ventas de productos con calcio**


```{r , echo=TRUE}
ModeloP_CALCIO_dummy = 
  glm(VENTAS~PRECIO_MEDIO_IMPUESTOS+
             (LUNES+MARTES+MIERCOLES+JUEVES+VIERNES+SABADO+DOMINGO)+
             (AGOSTO+SEPTIEMBRE+OCTUBRE+NOVIEMBRE+DICIEMBRE+ENERO),
            family = poisson(link = "log"),
            data=Ventas_CALCIO_ENT_poiss)
#summary(ModeloP_CALCIO_dummy)


ModeloP_CALCIO_factor= 
  glm(VENTAS~PRECIO_MEDIO_IMPUESTOS+DIA_SEMANA*MES,
             family = poisson(link = "log"),
             data=Ventas_CALCIO_ENT)
#summary(ModeloP_CALCIO_factor)
```

Para ambos modelos podemos afirmar:

- La variable precio medio es altamente significativa, un aumento de esta variable en un euro indicará una leve disminución de las ventas 
- La mayoría de las variables introducidas son significativas al 95% en el modelo

Además, para el modelo entrenado para el conjunto de datos con varaibles factorizadas, la interacción entre el día de la semana y el mes es significativa, indicando una variación de las ventas en función de las distintas combinaciones de valores de estas variables.


De nuevo, el modelo seleccionado es el modelo para variables factorizadas, que nos da el menor valor del AIC, indicación de una mayor calidad del modelo estadístico.

- $AIC_{dummies}=$ `r ModeloP_CALCIO_dummy$aic`
- $AIC_{factorizacion}=$ `r ModeloP_CALCIO_factor$aic`





Entrenamos el modelo seleccionado en los datos de entrenamiento haciendo uso de la función *predict* y mostramos en forma de tabla las métricas obtenidas para el conjunto de entrenamiento y el de testeo:

```{r , fig.pos = 'h'}
PRED_VOL_VENTAS_CALCIO=predict(ModeloP_CALCIO_factor, newdata = Ventas_CALCIO_TEST, type = "response")

RMSE_Ent_C=rmse(Ventas_CALCIO_ENT$VENTAS,predict(ModeloP_CALCIO_factor, newdata = Ventas_CALCIO_ENT, type = "response"))
R2_Ent_C=RSQUARE(Ventas_CALCIO_ENT$VENTAS,predict(ModeloP_CALCIO_factor, newdata = Ventas_CALCIO_ENT, type = "response"))

RMSE_Test_C = rmse(Ventas_CALCIO_TEST$VENTAS,PRED_VOL_VENTAS_CALCIO)
R2_Test_C =RSQUARE(Ventas_CALCIO_TEST$VENTAS,PRED_VOL_VENTAS_CALCIO)

DATOS_C = c("Datos entrenamiento","Datos Test")
R2_C=c(R2_Ent_C,R2_Test_C)
RMSE_C=c(RMSE_Ent_C,RMSE_Test_C)

cbind.data.frame(DATOS_C,R2_C,RMSE_C) %>% 
  kable(booktabs=TRUE) %>% 
  kableExtra::kable_styling(latex_options = c("striped","HOLD_position") )
```





Volvemos a tener unos resultados pobres, el modelo es capaz de explicar el `r R2_C[2]*100`% de la variabilidad del volumen de ventas para los datos de testeo, a pesar de explicar el `r R2_C[1]*100`% de la la variabilidad para los datos de entrenamiento, es decir, el modelo ha "*aprendido*" los datos con los que ha entrenado pero no generaliza bien para nuevos datos.



El p-valor del test de bondad de ajuste: `r pchisq(ModeloP_CALCIO_factor$deviance, df=ModeloP_CALCIO_factor$df.residual, lower.tail=FALSE)` $< 0.05 = \alpha$ .No existen evidencias significativas para afirmar que se trate de un modelo adecuadao.






**Ventas de productos sin calcio**


```{r , echo=TRUE}
ModeloP_SIN_CALCIO_dummy = 
  glm(VENTAS~PRECIO_MEDIO_IMPUESTOS+
             (LUNES+MARTES+MIERCOLES+JUEVES+VIERNES+SABADO+DOMINGO)+
             (AGOSTO+SEPTIEMBRE+OCTUBRE+NOVIEMBRE+DICIEMBRE+ENERO),
     family = poisson(link = "log"),
     data=Ventas_SIN_CALCIO_ENT_poiss)
#summary(ModeloP_SIN_CALCIO_dummy)


ModeloP_SIN_CALCIO_factor= 
  glm(VENTAS~PRECIO_MEDIO_IMPUESTOS+DESCUENTO_MEDIO+
        DIA_SEMANA*MES,
      family = poisson(link = "log"),
      data=Ventas_SIN_CALCIO_ENT)
#summary(ModeloP_SIN_CALCIO_factor)
```

Para ambos modelos podemos afirmar:

- La variable precio medio es altamente significativa en ambos modelos, indicando que un aumento de esta variable en un euro indicará una leve disminución de las ventas 
- Gran parte de las variables son significativas en el modelo

Además, para el modelo entrenado para el conjunto de datos con varaibles factorizadas, la interacción entre el día de la semana y el mes es significativa, indicando una variación de las ventas en función de las distintas combinaciones de valores de estas variables.


De nuevo, el modelo seleccionado es el modelo para variables factorizadas, que nos da el menor valor del AIC, indicación de una mayor calidad del modelo estadístico.

- $AIC_{dummies}=$ `r ModeloP_SIN_CALCIO_dummy$aic`
- $AIC_{factorizacion}=$ `r ModeloP_SIN_CALCIO_factor$aic`





Entrenamos el modelo seleccionado en los datos de testeo haciendo uso de la función *predict* y mostramos los resultados a modo de tabla:

```{r , fig.pos = 'h'}
PRED_VOL_VENTAS_SIN_CALCIO=predict(ModeloP_SIN_CALCIO_factor, newdata = Ventas_SIN_CALCIO_TEST, type = "response")


RMSE_Ent_SC=rmse(Ventas_SIN_CALCIO_ENT$VENTAS,predict(ModeloP_SIN_CALCIO_factor, newdata = Ventas_SIN_CALCIO_ENT, type = "response"))
R2_Ent_SC=RSQUARE(Ventas_SIN_CALCIO_ENT$VENTAS,predict(ModeloP_SIN_CALCIO_factor, newdata = Ventas_SIN_CALCIO_ENT, type = "response"))

RMSE_Test_SC = rmse(Ventas_SIN_CALCIO_TEST$VENTAS,PRED_VOL_VENTAS_SIN_CALCIO)
R2_Test_SC =RSQUARE(Ventas_SIN_CALCIO_TEST$VENTAS,PRED_VOL_VENTAS_SIN_CALCIO)

DATOS_SC = c("Datos entrenamiento","Datos Test")
R2_SC=c(R2_Ent_SC,R2_Test_SC)
RMSE_SC=c(RMSE_Ent_SC,RMSE_Test_SC)

cbind.data.frame(DATOS_SC,R2_SC,RMSE_SC) %>% 
  kable(booktabs=TRUE) %>% 
  kableExtra::kable_styling(latex_options = c("stripedf","HOLD_position") )
```



Volvemos a tener unos resultados no demasiado buenos. Este modelo no es capaz de explicar más que el `r R2_SC[2]*100`% de la variabilidad del volumen de ventas en los datos de testeo, a pesar de explicar el `r R2_SC[1]*100`% para los datos de entrenamiento. Los errores cuadráticos medios son muy elevados en comparación con el volumen de ventas que se está prediciendo.



El p-valor del contraste de bondad de ajuste: `r pchisq(ModeloP_SIN_CALCIO_factor$deviance, df=ModeloP_SIN_CALCIO_factor$df.residual, lower.tail=FALSE)` $< 0.05 = \alpha$ . No existen evidencias significativas para afirmar que se trate de un modelo adecuadao.



**Sobredispersión**


Estos modelos se han desarrollando asumiendo que la distribución de las ventas diarias sigue una Poisson, caracterizándose esta distribución porque su esperanza y su varianza coinciden; pero esto no siempre ocurre trabajando con conjuntos de datos reales. Se dice entonces que el modelo presenta sobredispersión. Vamos a contrastar la presencia de sobredispersión en los modelos entrenados haciendo uso de la función *dispersiontest* de la librería *AER*-



```{r}
dispersiontest(ModeloP_TOT_factor)
dispersiontest(ModeloP_CALCIO_factor)
dispersiontest(ModeloP_SIN_CALCIO_factor)
```


Concluímos que todos los casos existe dispersión y junto con las conlusiones de los test de bondad de ajuste, podemos afirma que en este caso, el modelo de regresión de poisson no es adecuaado para modelar el volumen de ventas diario.






##### Modelo de Regresión Binomial Negativa

Ante el problema de la sobredispersión, trataremos de modelare las ventas diarias según un modelo de regresión binomial negativa. No podemos hace uso de la función **glm** del paquete base de R debido a que no tiene implementada la opción de esta distribución. Por ello, utilizaremos la función **glm.nb** de la librería *MASS*, que incluye la estimación del parámetro de dispersión $\theta$.
Los conjuntos de datos son los mismos que los utilizados en los modelos de regresión de poisson, al igual que las variables explicativas:

- Variables dummy/factorizadas del día de la semana y el mes del año
- Precio medio con impuestos y descuento
- Día de la semana
- Mes del año



###### Modelado




**Ventas totales**


```{r , echo=TRUE }

ModeloBN_TOT_dummy = 
  glm.nb(VENTAS~PRECIO_MEDIO_IMPUESTOS+DESCUENTO_MEDIO+
              (LUNES+MARTES+MIERCOLES+JUEVES+VIERNES+SABADO+DOMINGO)+
              (AGOSTO+SEPTIEMBRE+OCTUBRE+NOVIEMBRE+DICIEMBRE+ENERO),
      data=Ventas_TOTAL_ENT_poiss)
summary(ModeloBN_TOT_dummy)
```


Con la función *glm.nb*, obtenemos una salida parecida a la del modelo de regresión de poisson salvo por el parámetro de dispersión $\theta$, estimado mediante el método de la máxima verosimilitud, para el cual se obtiene un valor que no es el que aparece en la salida, sino su inversa: $\theta=$ `r 1/ModeloBN_TOT_dummy$theta`.

También podemos ver la estimación de los coeficientes del modelo y el estadístico de desviación, que sigue una distribución chi-cuadrado de 130 grados de libertad y tiene un valor de 149.24. Haciendo uso de este estadístico podemos evaluar la sobredispersión de los datos de la siguiente forma:



\[\dfrac{D}{gl} \implies \dfrac{149.24}{130}=1.148>1\], 

La relación anterior nos indica sobredispersión en los datos.


En este modelo, para un nivel de signifiación del 95%, los coeficientes estimados para las varaibles descuento y precio medio pueden suponerse nulos, siendo en ambos casos el p-valor correspondiente mayor que $\alpha=0.05$. Tampoco es significativo el mes del año, es decir, para este modelo, las única variable que influyen en el volumen de venta es el día de la semana.


Vamos ahora a entrenar el modelo para las variables factorizadas:

```{r , echo=TRUE}
ModeloBN_TOT_factor= glm.nb(VENTAS~PRECIO_MEDIO_IMPUESTOS+
                          DIA_SEMANA+MES+DESCUENTO_MEDIO,
                       data=Ventas_TOTAL_ENT)
summary(ModeloBN_TOT_factor)
```

La única variable significativa de este modelo es que el haber realizado la compra un Domingo. La estimación del coeficiente es: $\hat\beta_{\text{Domingo}}=-2.542272<0$ y podemos afirmar lo siguiente: ir a comprar un Domingo, hará que el volumen de ventas disminuya ligeramente.



Para seleccionar un modelo adecuado, se ha hecho uso del criterio de información de Akaike, eligiendo aquel que nos de el menor AIC. A continuación se exponen los correspondientes valores del AIC para ambos modelos:

- Modelo con variables dummy: AIC= `r ModeloBN_TOT_factor$aic`
- Modelo con variables factorizadas: AIC= `r ModeloBN_TOT_dummy$aic`

Ambos modelos tienen el mismo valor del AIC, pero seleccionamos el de las varaibles dummy, ya que hay mayor número de variables significas en el modelo.


El siguiente pasao es entrenar el modelo seleccionado en los datos de testeo haciendo uso de la función *predict*. De nuevo, mostraremos el rendimiento de las métricas a modo de tabla:

```{r , fig.pos = 'h'}
PRED_VOL_VENTAS_TOTAL_BN=round(predict(ModeloBN_TOT_dummy, newdata = Ventas_TOTAL_TEST_poiss, type = "response"))


RMSE_Ent=rmse(Ventas_TOTAL_ENT_poiss$VENTAS,
              round(predict(ModeloBN_TOT_dummy, newdata = Ventas_TOTAL_ENT_poiss, type = "response")) ) 
R2_Ent=RSQUARE(Ventas_TOTAL_ENT$VENTAS,
            round(predict(ModeloBN_TOT_dummy, newdata = Ventas_TOTAL_ENT_poiss, type = "response")))

RMSE_Test = rmse(Ventas_TOTAL_TEST_poiss$VENTAS,PRED_VOL_VENTAS_TOTAL_BN)
R2_Test =RSQUARE(Ventas_TOTAL_TEST_poiss$VENTAS,PRED_VOL_VENTAS_TOTAL_BN)

DATOS = c("Datos entrenamiento","Datos Test")
R2=c(R2_Ent,R2_Test)
RMSE=c(RMSE_Ent,RMSE_Test)

Tabla1=cbind.data.frame(DATOS,R2,RMSE) %>% 
  kable(booktabs=TRUE, col.names = c("Datos","R2","RMSE")) %>% 
  kableExtra::kable_styling(latex_options = c("striped","HOLD_position") )
Tabla1
```

El modelo obtenido explica el `r round(100*R2_Ent,2)`% de la variabilidad total de los datos en el conjunto de entrenamiento, y el `r round(100*R2_Test,2)`% para los datos de testeo.  El valor del error cuadrático medio indica que el modelo se va a equivocar de media, en `r round(RMSE[2])` ventas, que es un valor alto para el volumen de ventas que se está considerando, ya que hay días que se venden menos de 700 items.






**Ventas de productos con calcio**


```{r , echo=TRUE}
ModeloBN_CALCIO_dummy = 
  glm.nb(VENTAS~PRECIO_MEDIO_IMPUESTOS+
             (LUNES+MARTES+MIERCOLES+JUEVES+VIERNES+SABADO+DOMINGO)+
             (AGOSTO+SEPTIEMBRE+OCTUBRE+NOVIEMBRE+DICIEMBRE+ENERO),
            data=Ventas_CALCIO_ENT_poiss)
#summary(ModeloBN_CALCIO_dummy)


ModeloBN_CALCIO_factor= 
  glm(VENTAS~PRECIO_MEDIO_IMPUESTOS+DIA_SEMANA+MES,
             data=Ventas_CALCIO_ENT)
#summary(ModeloBN_CALCIO_factor)
```

- Para ambos modelos podemos afirmar que el mes del año no influye en el volumen de ventaas

- En el modelo con variables factorizadas volvemos a comprobar que la única varaible significativa al 95%, y por tanto, la única cuyo coeficiente no es nulo es si la compra se ha realizado o no un Domingo.

- Sobredispersión del modelo con variables dummies: $\dfrac{D}{gl} \implies \dfrac{150.50}{132}=1.14>1$. Existe sobredispersión.


De nuevo, el modelo seleccionado es el modelo que utiliza variable dummies, que nos da el menor valor del AIC, indicación de una mayor calidad del modelo estadístico.

- $AIC_{dummies}=$ `r ModeloBN_CALCIO_dummy$aic`
- $AIC_{factorizacion}=$ `r ModeloBN_CALCIO_factor$aic`





Entrenamos el modelo seleccionado en los datos de entrenamiento haciendo uso de la función *predict*

```{r}
PRED_VOL_VENTAS_CALCIO_BN=predict(ModeloBN_CALCIO_dummy, newdata = Ventas_CALCIO_TEST_poiss, type = "response")
```



En el siguiente gráfico podemos ver una representación de los valores observados respecto de los valores ajustados.





```{r}
RMSE_Ent_C=rmse(Ventas_CALCIO_ENT_poiss$VENTAS,predict(ModeloBN_CALCIO_dummy, newdata = Ventas_CALCIO_ENT_poiss, type = "response"))
R2_Ent_C=RSQUARE(Ventas_CALCIO_ENT_poiss$VENTAS,predict(ModeloBN_CALCIO_dummy, newdata = Ventas_CALCIO_ENT_poiss, type = "response"))

RMSE_Test_C = rmse(Ventas_CALCIO_TEST_poiss$VENTAS,PRED_VOL_VENTAS_CALCIO_BN)
R2_Test_C =RSQUARE(Ventas_CALCIO_TEST_poiss$VENTAS,PRED_VOL_VENTAS_CALCIO_BN)

DATOS_C = c("Datos entrenamiento","Datos Test")
R2_C=c(R2_Ent_C,R2_Test_C)
RMSE_C=c(RMSE_Ent_C,RMSE_Test_C)

Tabla2= cbind.data.frame(DATOS_C,R2_C,RMSE_C) %>% 
  kable(booktabs=TRUE, col.names = c("Datos","R2","RMSE")) %>% 
  kableExtra::kable_styling(latex_options = c("striped","HOLD_position") )
Tabla2
```


Este modelo es capaz de explicar el `r R2_C[2]`% de la variabilidad del volumen de ventas para los datos de testeo, a pesar de explicar el `r R2_C[1]`% de la la variabilidad para los datos de entrenamiento. A pesar de obtener estos resultados, el error cuadrático medio cometido es menor en los datos de testeo, pero aún bastante alto para el volumen de ventas diario de los productos con calcio.







**Ventas de productos sin calcio**


```{r , echo=TRUE}
ModeloBN_SIN_CALCIO_dummy = 
  glm.nb(VENTAS~PRECIO_MEDIO_IMPUESTOS+
             (LUNES+MARTES+MIERCOLES+JUEVES+VIERNES+SABADO+DOMINGO)+
             (AGOSTO+SEPTIEMBRE+OCTUBRE+NOVIEMBRE+DICIEMBRE+ENERO),
     data=Ventas_SIN_CALCIO_ENT_poiss)
# summary(ModeloBN_SIN_CALCIO_dummy)


ModeloBN_SIN_CALCIO_factor= 
  glm.nb(VENTAS~PRECIO_MEDIO_IMPUESTOS+DESCUENTO_MEDIO+
        DIA_SEMANA+MES,
      data=Ventas_SIN_CALCIO_ENT)
# summary(ModeloBN_SIN_CALCIO_factor)
```

Se han obtenido resultados muy similares al resto:


- Para ambos modelos podemos afirmar que el mes del año no influye en el volumen de ventaas

- En este caso, para el modelo con variables factorizadas existen dos varaibles significativas que sea Domingo o Miércoles.

- Sobredispersión del modelo: $\dfrac{D}{gl} \implies \dfrac{149.92}{132}=1.13>1$. Existe sobredispersión. Nota: estos grados de libertad son los del modelo con variables dummies, pero en el segundo modelo, el estadístico de desviación tiene 131 grados de libertad, y por tanto, el resultado es el mismo.



El modelo seleccionado es el modelo que utiliza variable dummies, que nos da el menor valor del AIC, indicación de una mayor calidad del modelo estadístico.

- $AIC_{dummies}=$ `r ModeloBN_SIN_CALCIO_dummy$aic`
- $AIC_{factorizacion}=$ `r ModeloBN_SIN_CALCIO_factor$aic`






Entrenamos el modelo seleccionado en los datos de entrenamiento haciendo uso de la función *predict*.

```{r}
PRED_VOL_VENTAS_SIN_CALCIO_BN=predict(ModeloBN_SIN_CALCIO_dummy, newdata = Ventas_SIN_CALCIO_TEST_poiss, type = "response")
```






```{r}

RMSE_Ent_SC=rmse(Ventas_SIN_CALCIO_ENT_poiss$VENTAS,
                 predict(ModeloBN_SIN_CALCIO_dummy, newdata = Ventas_SIN_CALCIO_ENT_poiss, type = "response"))

R2_Ent_SC=RSQUARE(Ventas_SIN_CALCIO_ENT_poiss$VENTAS,
                  predict(ModeloBN_SIN_CALCIO_dummy, newdata = Ventas_SIN_CALCIO_ENT_poiss, type = "response"))

RMSE_Test_SC = rmse(Ventas_SIN_CALCIO_TEST_poiss$VENTAS,PRED_VOL_VENTAS_SIN_CALCIO_BN)
R2_Test_SC =RSQUARE(Ventas_SIN_CALCIO_TEST_poiss$VENTAS,PRED_VOL_VENTAS_SIN_CALCIO_BN)

DATOS_SC = c("Datos entrenamiento","Datos Test")
R2_SC=c(R2_Ent_SC,R2_Test_SC)
RMSE_SC=c(RMSE_Ent_SC,RMSE_Test_SC)

Tabla3= cbind.data.frame(DATOS_SC,R2_SC,RMSE_SC) %>% 
  kable(booktabs=TRUE, col.names = c("Datos","R2","RMSE")) %>% 
  kableExtra::kable_styling(latex_options = c("striped","HOLD_position") )
Tabla3
```



Este modelo no es capaz de explicar más que el `r R2_SC[2]*100`% de la variabilidad del volumen de ventas en los datos de testeo, explicando el `r R2_SC[1]*100`% de la variabilidad de ventas para los datos de entrenamiento. Los errores cuadráticos medios son muy elevados en comparación con el volumen de ventas que se está prediciendo.



**Comparación de las métricas obtenidas**

A continuación, mostramos una comparación del rendimiento de los diferentes modelos:


```{r}

T1=cbind.data.frame(DATOS,R2,RMSE) 
T2=cbind.data.frame(DATOS_C,R2_C,RMSE_C) 
T3=cbind.data.frame(DATOS_SC,R2_SC,RMSE_SC)  

colnames(T1) = c("Datos","R2","RMSE")
colnames(T2) = c("Datos","R2","RMSE")
colnames(T3) = c("Datos","R2","RMSE")

rbind(T1,T2,T3) %>% 
  kable(booktabs=TRUE) %>% 
  kable_styling(latex_options = c("striped","hold_position")) %>% 
  pack_rows("Suma de productos", 1, 2, latex_gap_space = "1em") %>% 
    pack_rows("Producto con calcio", 3, 4, latex_gap_space = "1em") %>% 
    pack_rows("Producto sin calcio", 5, 6, latex_gap_space = "1em")


```


Todos los modelos tienen un rendimiento similar y una capacidad de generalización similar.


**Comparación de las predicciones**

Mostramos un gráfico para comparar la predicción de ventas de la suma de productos con la suma de las predicciones de cada uno de los productos por separado:

```{r , fig.height=4}

Fecha = Ventas_SIN_CALCIO_TEST_poiss$FECHA
SumaPed = PRED_VOL_VENTAS_SIN_CALCIO_BN+PRED_VOL_VENTAS_CALCIO_BN
PredSuma = PRED_VOL_VENTAS_TOTAL_BN


Pred = c(SumaPed,PredSuma)
Tipo =c(rep("Suma de la predicción",length(SumaPed)),rep("Predicción de la suma",length(PredSuma)))




ggplot(cbind.data.frame(Pred,Tipo,Fecha) )+
  geom_line(aes(x=Fecha, y = Pred, group=Tipo, colour=Tipo)  ) +
  scale_x_date(date_labels = "%d %b %y",date_breaks = "15 days")+
  scale_y_continuous(breaks=seq(0,3000,by=500))+
  labs(x="Día" , y = "Predicicón de ventas", caption = "Fuente: Elaboración propia con datos de ventas")+
 theme_gray() +
  theme(axis.text.x = element_text(angle = 45))+
  ggtitle("Comparación del volumen de ventas")
  
```

Se observa que la suma de las predicciones individuales de cada producto ofrece unos arroja unas ventas ligeramente superiores que en la predicción considerando las ventas de ambos productos.



##### Conclusiones 



- El modelo de regresión de Poisson no es adecuado para modelar el volumen de ventas diarias, debido a la gran sobredispersión existente en los datos
- El mejor modelo de regresión Bonimial Negativa encontrado es para el volumen de ventas total, donde se consigue explicar un 37.73% de la variabilidad total de los datos. A pesar de ser el mejor, es un resultado bastante pobre.
- El formato de los datos que nos ha proporcionado mejores modelos de regresión binomial es el de las variables dummies
- Emplear un modelo de binomial negativa nos ha llevado a obtener mejores resultadaos, además de ser mas fiables y precisos que haciendo uso de la distribución de Poisson
- Un posible motivo para no obtener buenos resultados es la limitación que existente en los datos, ya que únicamente tenemos datos de ventas para 181 días, y los modelos no consiguien "*aprender*" como es el comportamiento de venta en función de las diferentes variables temporales o el precio de venta de los productos.





##### Análisis de Series Temporales

Se consideró aplicar un análisis de series temporales debido a la estructura de los datos, ya que este tipo de análisis contempla la estructura temporal de los mismos. Como ya se avanzó en el desarrollo teórico, aplicaremos la metodología Box-Jenkis, la cual tiene en cuenta la dependencia existente de los datos, construyendo así un modelo ARIMA.

Trataremos de modelizar el volumen de ventas total según día de la semana. Para construir la serie, primero hemos añadido los días 25 de Diciembre y 1 de Enero con un número de ventas 0, ya que, si no se tomaba esta decisión, la serie ya no estaría definida según la realidad.



###### Creación ST y representación de los datos


```{r}
# Para agrupar, cuento cuantos tickets únicos hay cada día
Ventas_Totales_Dia_Semana = as.data.frame ( dataset %>% group_by(FECHA,DIA_SEMANA, ID_TICKET) %>% dplyr::summarise(ArtVendidos = sum(CANTIDAD)) ) %>% group_by(FECHA) %>% dplyr::summarise(ArtVendidos = sum(ArtVendidos))

F1=as_date('2020-12-25')
df1 =  cbind.data.frame(F1,0)
colnames(df1)=colnames(Ventas_Totales_Dia_Semana)
F2=as_date('2021-01-01')
df2 =  cbind.data.frame(F2,0)
colnames(df2)=colnames(Ventas_Totales_Dia_Semana)



Ventas_Totales_Dia_Semana_Completo = rbind.data.frame( Ventas_Totales_Dia_Semana[1:146,],df1 , Ventas_Totales_Dia_Semana[147:152,],df2 , Ventas_Totales_Dia_Semana[153:181,] )
```

Los datos que se han utilizado para el análisis han sido las ventas totales para cada día, agrupando los datos según día de la semana, obteniendo así datos con período S=7. 

Sin embargo, si construimos la serie con los valores actuales, no podremos aplicarle transformaciones, en particular la transformación de Box-Cox, ya que existen dos valores nulos, las ventas para los días 25 de Diciembre y 1 de Enero. Por este motivo, sumamos una constante a todas las observaciones de modo que sean todas positivas.


*Nota*: la constante que hemos sumado es de 10 unidades.




```{r}
Ventas_Totales_Dia_Semana_Completo$ArtVendidos=
  10+Ventas_Totales_Dia_Semana_Completo$ArtVendidos
```

El primer dato, indica que el sábado de la semana 31 del año se vendieron un total de 2049 artículos, aunque en la realidad es que se vendieron 10 unidades menos, pero se le ha sumado una constante a la serie.


```{r, echo=TRUE}
tsDiaSemanal = ts(Ventas_Totales_Dia_Semana_Completo$ArtVendidos,
                  frequency=7, # Período
                  start=c(31,6) # Semana 36, sábado
                  ) 
print(tsDiaSemanal,calendar=TRUE)
```


Después de haber definido los datos como una serie temporal, visualizamos la evolución de la serie en el tiempo.

```{r}
plot(tsDiaSemanal, main = "Volumen total de venta por según día de la semana", xlab="Dia" , ylab = "Volumen de ventas")
```

En el gráfico se puede apreciar cierta estacionalidad de los datos, es decir, movimientos que se repiten regularmente año trás año en los mismo períodos. También observamos que las oscilaciones van aumentando con el tiempo, indicando que la varianza no es constante. Por este motivo, debemos hacer alguna transformación para que la varianza sea constante en el tiempo.

###### Transformación de BoxCox para estabilizar la varianza



Para encontrar una transformación que haga que la varianza sea constante en el tiempo, haremos uso de la familia de transformaciones Box-Cox con ayuda de la librería *TSA*. 


```{r , fig.height=4 , fig.width=6}
BoxCox =BoxCox.ar(y=tsDiaSemanal)
# BoxCox
```


La función *BoxCox.ar* sugiere un óptimo de $\lambda=$ `r BoxCox$mle`, con un intervalo de confianza al 95%: (`r BoxCox$c[1]`,`r BoxCox$c[2]`). Se necesita una transformación sencilla y comprensible, por lo que se ha obtado por tomar como valor de lambda el extremo inferior del intervalo, $\lambda=1/2$.

Transformamos los datos y volvemos a representar la serie.


```{r}
tsDiaSemanal_transf = sqrt(tsDiaSemanal)

plot(tsDiaSemanal_transf, main = "sqrt(Volumen total de venta diario)", xlab="Dia" , ylab = "sqrt(Volumen de ventas)")
```



###### Transformaciones para estabilizar la media



Vamos a estudiar si el motivo de la no estacionalidad de los datos en media se debe a que se trata de un proceso integrado. Para ello, hacemos uso de la función de autocorrelación simple.

```{r , fig.height=4}
acf(tsDiaSemanal_transf, main="FAS de SQRT de Ventas diarias" , lag=50)
```

La FAS muestral decrece de lentamente en los retardos estacionales de período 7, indicando que estamos ante un modelo integrado.  Debido a esta situación, hacemos una diferencia estacional de la serie y volvemos a representar la FAS (s=7).

```{r}
# ndiffs(tsDiaSemanal_transf) # num dif regulares necesarias en la serie para que sea estacionaria
# nsdiffs(tsDiaSemanal_transf) # num dif estarionarias necesarias en la serie para que sea estacionaria
```





```{r echo=TRUE, fig.height=4}
tsDiaria_DifEst = diff(tsDiaSemanal_transf,lag=7,diff=1)
acf(tsDiaria_DifEst, main="FAS de primera diferencia estacional", lag=50)
```


Ahora la función de autocorrelación muestral corresponde a la de un proceso estacionario. Por último, representamos gráficamente la serie diferenciada:

```{r}
plot(tsDiaria_DifEst)
```

Observamos que la serie no muestra ningún comportamiento en particular, sino que se aprecia aleatoriedad, por lo que se podría pensar, que nos encontramos ante un proceso estacionario. Ahora estamos en condiciones de buscar un modelo estacionario para la serie.


###### Contraste de estacionariedad

Para confirmar la estacionariedad de los datos sugerida con la observación de la gráfica, necesitamos aplicar un test de hipótesis. Aplicamos el test de raíz unitaria de Dikey-Fuller, donde se contrasta la estacionariedad de los datos a través del siguiente test de hipótesis:


\[
\left\{
\begin{array}{ll}
H_{0}: &  \text{El polinomio autoregresivo tiene una raíz unitaria}  \\
H_{1}: & \text{Todas las raíces del polinomio autoregresivo son estacionarias}
\end{array}
\right.
\]




```{r}
adf.test(tsDiaria_DifEst)
```

El p-valor del test= $0.01 < 0.05= \alpha$, y por tanto concluímos que no existen evidencias significativas para asumir que el polinomio autoregresivo tiene alguna raíz unitaria, la serie es estacionaria.


###### Identificación de la estructura ARIMA de la serie 

Trataremos de identificar la estructura ARIMA más adecuada para esta serie a través de la función de autocorrelación simple (FAC) y de la función de autocorrelación parcial (FAP). Determinar el modelo más adecuado consistirá en e identificar el orden de los procesos de medias móviles y autoregresivos de la componente estacional y la componente regular.


```{r , fig.height=4}
acf(tsDiaria_DifEst, main="FAS tras una diferencia estacional", lag=50)
```

- Parte regular: En los primeros retardos no observamos ninguna autocorrelación significativamente no nula, indicando que el modelo tiene una estructura ARMA(0,0) en la parte regular.


- Parte estacional: Observamos una autocorrelación en el primer retardo estacional, por lo que parecería que la parte estacional tiene una estructura $MA(1)_{12}$.

Vamos a comprobar estos supuestos con la FAP.


```{r , fig.height=4}

pacf(tsDiaria_DifEst, main="FAP tras una diferencia estacional", lag=50)
```



- Parte regular: De nuevo, no hay autocorrelaciones significativamente no nulas en los primeros retardos.

- Parte estacional: En los retardos estacionales, observamos como las autocorrelaciones decrecen rápidamente y a su izquierda, no hay autocorrelaciones significativamente no nulas, lo que avalaría aún más la suposición de un MA(1) en la parte estacional. Modelo propuesto: $MA(1)_{12}$



También observamos como hay otras autocorrelaciones significativamente no nulas, pero esto es debido a que se trata de un intervalo de confianza al 95%, por lo que cabe esperar que haya algunas autocorrelaciones fuera de las bandas.


El modelo a considerar es un modelo estacional multiplicativo integrado de medias móviles puro: $ARIMA(0,1,1)_{12}$



###### Estimación de parámetros y diagnóstico del modelo


Una vez hemos obtenido un modelo, se han estimado sus parámetros con la función *arima*.



```{r , echo=TRUE}
Ajuste1 = arima( tsDiaria_DifEst ,   # Serie trás una diferencia estacional
                 seasonal = list(order=c(0,0,1),period=7 ))
Ajuste1
```


Trás comprobar si los coeficientes estimados son o no significativamente nulos, procedemos a eliminar la media del modelo, obteniendo así uno donde todos los coeficientes son significativamente no nulos.


```{r}
confint(Ajuste1) # Intervalo de confianza 
```



```{r , echo=TRUE}
Ajuste1_1 = arima( tsDiaria_DifEst ,   # Serie trás una diferencia estacional
                   order = c(0,0,0),seasonal = list(order=c(0,0,1),period=7), 
                 include.mean = FALSE # Eliminamos la media
                 )
Ajuste1_1
confint(Ajuste1_1)
```

El modelo ajustado corresponde a la siguiente ecuación: \[Y_t =(1-L^7)(1+0.9999 \Theta^7)\alpha_t , \qquad \alpha_t \sim RB(0,\sigma^2) \]


Para comprobar si el modelo es o no adecuado, comprobamos su validez a través de la diagnosis de los resíduos y concluímos que este ajuste no es adecuado, ya que según el Test de Ljung-Box, no existen evidencias significativas para aceptar la incorrelación de los resíduos: p-valor = $0.002524<0.05 = \alpha$. Además, gráficamente podemos observar que los resíduos no se comportan como un ruido blanco.



```{r}
checkresiduals(Ajuste1_1, plot=FALSE)
```



```{r}
par(mfrow=c(2,2))
# Gráfica de los resíduos
plot(window(rstandard(Ajuste1_1),start=c(31,6)), 
     ylab='Resíduos estandarizados',type='o')
abline(h=0)
# FAS de los resíduos
acf(as.vector(window(rstandard(Ajuste1_1),
                     start=c(31,6))),lag.max=36,
    main="FAS de los resíduos")
# Histograma 
#win.graph(width=4, height=4,pointsize=8)
hist(window(rstandard(Ajuste1_1),start=c(31,6)),
   xlab='Resíduos estandarizados',
     main="Histograma")
# Gráfica QQ-Normal 
qqnorm(window(rstandard(Ajuste1_1),start=c(31,6)))
qqline(window(rstandard(Ajuste1_1),start=c(31,6)))
```



Vamos a probar otro modelo, en particular, a través del paquete *forecast* haciendo uso de la función *auto.arima*, que busca un modelo que minimiza el AIC.




```{r}
ajuste2 = auto.arima(tsDiaSemanal_transf,d = 0,D=1)
ajuste2
```


```{r}
checkresiduals(ajuste2)
```



El ajuste propuesto es un modelo: $ARIMA(1,0,0)xARIMA(2,0,0)_{7}$, pero tampoco es adecuado, ya que volvemos a rechazar la hipótesis de incorrelación de los resíduos del Test de Ljung-Box.



No hemos podido encontrar un modelo adecuado que se ajuste a los datos y que pase la diagnosis, ya que los resíduos no provenían en ningún caso de un proceso de ruido blanco, es decir, no estaban incorrelados entre sí. Por este motivo, al no ser los retardos independientes, un retardo puede guardar cierta relación con otro retardo k períodos después. En estos casos, la autocorrelación puede conducir a una inexactitud en el modelo predictivo, que nos llevaría a interpretaciones erróneas.

La tabla mostrada a continuación expone los diferentes modelos ajutado, el valor del AIC y el p-valor obtenido del test de Ljung-Box. De haber pasado algún modelo la diagnosis, el seleccionado para realizar predicciones del volumen de ventas habría sido aquel con menor valor del AIC.


```{r , include=FALSE}
A1 = checkresiduals(Ajuste1_1, plot=FALSE)
p.valor1= A1$p.value
modelo1= "ARIMA(0,1,1)_7"
aic1=Ajuste1_1$aic

A2 = checkresiduals(ajuste2, plot=FALSE)
p.valor2= A2$p.value
modelo2="ARIMA(1,0,0)x(2,1,0)_7 "
aic2=ajuste2$aicc

Ajuste3 = arima( tsDiaria_DifEst ,   # Serie trás una diferencia estacional
                   order = c(0,0,0),
                 seasonal = list(order=c(1,0,1),period=7) )
A3= checkresiduals(Ajuste3, plot=FALSE)
p.valor3=A3$p.value
modelo3="ARIMA(1,1,1)_7"
aic3=Ajuste3$aic  

Ajuste4 = arima( tsDiaria_DifEst ,   # Serie trás una diferencia estacional
                   order = c(0,0,0),
                 seasonal = list(order=c(1,0,0),period=7),
                 include.mean = FALSE)
A4= checkresiduals(Ajuste4, plot=FALSE)
p.valor4=A4$p.value
modelo4="ARIMA(1,1,0)_7"
aic4=Ajuste4$aic
```


```{r }
p.valor=c(p.valor1,p.valor2,p.valor3,p.valor4)
aic=c(aic1,aic2,aic3,aic4)
modelo=c(modelo1,modelo2,modelo3,modelo4)

comparacion_moodelos = cbind.data.frame(modelo,aic,p.valor)
rownames(comparacion_moodelos)=c("Modelo 1","Modelo 2","Modelo 3","Modelo 4")
comparacion_moodelos %>% 
  kable(booktabs=TRUE,col.names = c("MODELO","AIC","p-valor")) %>% 
  kable_styling(latex_options = c("striped" ,"HOLD_position") ) %>% 
  footnote(general = "El p-valor corresponde al test de Ljung-Box" )
```

















