---
author: "Nombre Completo Autor"
date: "27/10/2017"
documentclass: book
forprint: true  # true: imprime a dos caras, false: libro digital
fontsize: 12pt # 10pt,11pt
geometry: margin = 2.5cm 
bibliography: ["bib/library.bib", "bib/paquetes.bib"]
# metodobib -> true: natbib (descomentar: citation_package: natbib) 
#           -> false: pandoc (comentar: citation_package: natbib)
metodobib: true
#natbib: plainnat, abbrvnat, unsrtnat
biblio-style: "plainnat"
#Método 2 (pandoc): descomente una línea de las 2 siguientes en caso de usarlo
csl: methods-in-ecology-and-evolution.csl      # no numera mejor en las citas
#csl: acm-sig-proceedings-long-author-list.csl  # numera peor en las citas
link-citations: yes
output: 
  pdf_document:
    keep_tex: no
    number_sections: yes
    citation_package: natbib  # comentado usa: pandoc-citeproc
    #toc: yes
    fig_caption: yes
    template: latex/templateMemoriaTFE.tex
    includes:
      #before_body: portadas/latex_paginatitulo_modTFE.tex
      #in_header: latex/latex_preambulo.tex
      #after_body: latex/latex_antes_enddoc.tex
---

```{r  }
knitr::opts_chunk$set(echo = FALSE , warning = FALSE , message = FALSE )
```

```{r , message=FALSE , echo= FALSE}
library(tidyverse)
library(dplyr)
library(kableExtra)

library(plyr) # Transformación de los datos
library(dplyr)


library(lubridate)
library(ggplot2) # Visualización
library(hrbrthemes) # Temas 

library(TSA) # Series Temporales (B-C) (Not working)
library(tseries) # Test de raíz unitaria
library(forecast) # Diagnosis del modelo

```




## Modelos estadísticos clásicos



```{r }
load("Datos/Dataset_Final.RData")
```





### Modelo de Regresión Lineal General

### Análisis de Series Temporales

Se consideró aplicar un análisis de series temporales debido a la estructura de los datos. ya que este tipo de análisis contempla la estructura temporal de los mismos Como ya se avanzó en el desarrollo teórico, aplicaremos la metodología Box-Jenkis, la cual tiene en cuenta la dependencia existente de los datos, construyendo así un modelo ARIMA.

Trataremos de modelizar el volumen de ventas total según por de la semana. Para construir la serie, primero hemos añadido los días 25 de Diciembre y 1 de Enero con un número de ventas 0, ya que, si no se tomaba esta decisión, la serie ya no estaría definida según la realidad.


#### Creación ST y representación de los datos


```{r}
# Para agrupar, cuento cuantos tickets únicos hay cada día
Ventas_Totales_Dia_Semana = as.data.frame ( dataset %>% group_by(FECHA,DIA_SEMANA, ID_TICKET) %>% dplyr::summarise(ArtVendidos = sum(CANTIDAD)) ) %>% group_by(FECHA) %>% dplyr::summarise(ArtVendidos = sum(ArtVendidos))

F1=as_date('2020-12-25')
df1 =  cbind.data.frame(F1,0)
colnames(df1)=colnames(Ventas_Totales_Dia_Semana)
F2=as_date('2021-01-01')
df2 =  cbind.data.frame(F2,0)
colnames(df2)=colnames(Ventas_Totales_Dia_Semana)



Ventas_Totales_Dia_Semana_Completo = rbind.data.frame( Ventas_Totales_Dia_Semana[1:146,],df1 , Ventas_Totales_Dia_Semana[147:152,],df2 , Ventas_Totales_Dia_Semana[153:181,] )
```



Si construimos la serie con los valores actuales, no podremos aplicar transformaciones a la serie, en particuar la transformación de Box-Cox, ya que existen dos valores nulos. Por este motivo, sumamos una constante a todas las observaciones de modo que sean todas positivas.


```{r}
Ventas_Totales_Dia_Semana_Completo$ArtVendidos=10+Ventas_Totales_Dia_Semana_Completo$ArtVendidos
tsDiaSemanal = ts(Ventas_Totales_Dia_Semana_Completo$ArtVendidos, frequency=7,start=c(31,6)) 
print(tsDiaSemanal,calendar=TRUE)
```


Después de haber definido los datos como una serie temporal, visualizamos la evolución de la serie en el tiempo.

```{r}
plot(tsDiaSemanal, main = "Volumen total de venta por día de la semana", xlab="Dia" , ylab = "Volumen de ventas")
```

En el gráfico se puede apreciar cierta estacionalidad de los datos, es decir, movimientos que se repiten regularmente año trás año en los mismo períodos. También observamos que las oscilaciones van aumentando con el tiempo, indicando que la varianza no es constante. Por este motivo, debemos hacer alguna transformación para que la varianza sea constante en el tiempo.

#### Transformación de BoxCox para estabilizar la varianza



Para encontrar una transformación que haga que la varianza sea constante en el tiempo, haremos uso de la familia de transformaciones Box-Cox con ayuda de la librería *TSA*. 


```{r}
BoxCox =BoxCox.ar(y=tsDiaSemanal)
# BoxCox
```


La función *BoxCox.ar* sugiere un óptimo de $\lambda=$. `r BoxCox$mle`, con un intervalo de confianza al 95%: (`r BoxCox$c[1]`,`r BoxCox$c[2]`). Se necesita una transformación sencilla y comprensible, por lo que se ha obtado por tomar como valor de lambda el extremo inferior del intervalo,$\lambda=1/2$.

Transformamos los datos y volvemos a representar la serie.


```{r}
tsDiaSemanal_transf = sqrt(tsDiaSemanal)
plot(tsDiaSemanal_transf, main = "sqrt(Volumen total de venta diario)", xlab="Dia" , ylab = "sqrt(Volumen de ventas)")
```



#### Transformaciones para estabilizar la media



Vamos a estudiar si el motivo de la no estacionalidad de los datos en media se debe a que se trata de un proceso integrado. Para ello hacemos uso de la función de correlación simple.

```{r}
acf(tsDiaSemanal_transf, main="FAS de SQRT de Ventas diarias" , lag=50)
```

La FAS muestral decrece de lentamente en los retardos estacionales de período 7, indicando que estamos ante un modelo integrado.  Debido a esta situación, hacemos una diferencia estacional de la serie.

```{r}
# ndiffs(tsDiaSemanal_transf) # num dif regulares necesarias en la serie para que sea estacionaria
# nsdiffs(tsDiaSemanal_transf) # num dif estarionarias necesarias en la serie para que sea estacionaria
```



El siguiente gráfico muestra la FAS tras haber hecho una diferencia estacional de la serie (s=7).

```{r}
tsDiaria_DifEst = diff(tsDiaSemanal_transf,lag=7,diff=1)
acf(tsDiaria_DifEst, main="FAS de primera diferencia estacional", lag=50)
```


Ahora la función de autocorrelación muestral corresponde a la de un proceso estacionario. Por último, representamos gráficamente la serie diferenciada:

```{r}
plot(tsDiaria_DifEst)
```

Observamos que la serie no muestra ningún comportamiento en particular, sino que se aprecia aleatoriedad, por lo que se podría pensar, que nos encontramos ante un proceso estacionario. Ahora estamos en condiciones de buscar un modelo estacionario para la serie.


#### Contraste de estacionariedad

Para confirmar la estacionariedad de los datos sugerida con la observación de la gráfica, necesitamos a plicar un test de hipótesis. Aplicamos el test de raíz unitaria de Dikey-Fuller, donde se contrasta la estacionariedad de los datos a través del siguiente contraste de hipótesis:


\[
\left\{
\begin{array}{ll}
H_{0}: &  \text{El polinomio autoregresivo tiene una raíz unitaria}  \\
H_{1}: & \text{Todas las raíces del polinomio autoregresivo son estacionarias}
\end{array}
\right.
\]




```{r}
adf.test(tsDiaria_DifEst)
```

El p-valor del test= $0.01 < 0.05= \alpha$, y por tanto concluímos que no existen evidencias significativas para asumir que el polinomio autoregresivo tiene alguna raíz unitaria, y por tanto, la serie es estacionaria.


#### Identificación de la estructura ARIMA de la serie 

Trataremos de identificar la estructura ARIMA a través de la función de autocorrelación simple (FAC) y de la función de autocorrelación parcial (FAP).


```{r}
acf(tsDiaria_DifEst, main="FAS tras una diferencia estacional", lag=50)
```

- Parte regular: En los primeros retardos no observamos ninguna autocorrelación significativamente no nula, indicando que el modelo tiene una estructura ARMA(0,0) en la parte regular.


- Parte estacional: Observamos una autocorrelación en el primer retardo estacional, por lo que parecería que la parte estacional tiene una estructura $MA(1)_{12}$.

Vamos a comprobar estos supuestos con la FAP.


```{r}

pacf(tsDiaria_DifEst, main="FAP tras una diferencia estacional", lag=50)
```



- Parte regular: De nuevo, no hay autocorrelaciones significativamente no nulas.

- Parte estacional: En los retardos estacionales, observamos como las autocorrelaciones decrecen rápidamente y a su izquierda, no hay autocorrelaciones significativamente no nulas, lo que avalaría aún más la suposición de un MA(1) en la parte estacional. Modelo propuesto: $MA(1)_{12}$



También observamos como hay otras autocorrelaciones significativamente no nulas, pero esto es debido a que se trata de un intervalo de confianza al 95%, por lo que cabe esperar que haya algunas autocorrelaciones fuera de las bandas.


El modelo a considerar es un modelo estacional puro: $ARIMA(0,1,1)_{12}$



#### Estimación de parámetros y diagnóstico





```{r , echo=TRUE}
Ajuste1 = arima( tsDiaria_DifEst ,   # Serie trás una diferencia estacional
                 seasonal = list(order=c(0,0,1),period=7))
Ajuste1
```


Trás comprobar si los coeficientes estimados son o no significativamente nulos, procedemos a eliminar la media del modelo, obteniendo así uno donde todos los coeficientes son significativamente no nulos.

```{r}
confint(Ajuste1)
```



```{r , echo=TRUE}
Ajuste1_1 = arima( tsDiaria_DifEst ,   # Serie trás una diferencia estacional
                   order = c(0,0,0),
                 seasonal = list(order=c(0,0,1),period=7), include.mean = FALSE
                 )
Ajuste1_1
```




```{r}
confint(Ajuste1_1)
```


Para comprobar si el modelo es o no adecuado, comprobamos su valided a través de la diagnosis de los resíduos.
Para este ajuste, según el Test de Ljung-Box, no existen evidencias significativas para aceptar la incorrelación de los resíduos: p-valor = $0.002524<0.05 = \alpha$. Además, gráficamente podemos observar que los resíduos no se comportan como un ruido blanco.

```{r}
checkresiduals(Ajuste1_1,plot = TRUE)
```



Vamos a probar otro modelo, en particular, a través del paquete *forecast* haciendo uso de la función *auto.arima*, que busca un modelo que minimiza el AIC.




```{r}
ajuste2 = auto.arima(tsDiaSemanal_transf,d = 0,D=1)
```


```{r}
ajuste2
```


```{r}
checkresiduals(ajuste2)
```



El ajuste propuesto es un modelo: $ARIMA(1,0,0)xARIMA(2,0,0)_{7}$, pero tampoco es adecuado, ya que volvemos a rechazar la hipótesis de incorrelación de los resíduos del Test de Ljung-Box.

No encontramos modelo adecuado.




